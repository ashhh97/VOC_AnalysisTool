#!/usr/bin/env python3
from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS
import os
import uuid
import openpyxl
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
import json
import threading
import time
import queue
from voc_analyzer import VOCAnalyzer

app = Flask(__name__)
CORS(app)

UPLOAD_FOLDER = os.path.join(os.path.dirname(__file__), 'uploads')
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

analyzer = VOCAnalyzer()

# ç”¨äºè·Ÿè¸ªåˆ†æä»»åŠ¡çš„çŠ¶æ€
# ç”¨äºè·Ÿè¸ªåˆ†æä»»åŠ¡çš„çŠ¶æ€
analysis_tasks = {}  # {file_id: {'stop_flag': threading.Event(), 'thread': thread}}

@app.route('/api/log_feedback', methods=['POST'])
def log_feedback():
    try:
        data = request.json
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        # Log to file
        log_file = os.path.join(os.path.dirname(__file__), 'training_data.jsonl')
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(data, ensure_ascii=False) + '\n')
            
        print(f"[Feedback] Logged implicit feedback: {data.get('event_type')}")
        return jsonify({'status': 'success', 'message': 'Feedback logged'}), 200
    except Exception as e:
        print(f"[Feedback] Error logging feedback: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/recalculate_stats', methods=['POST'])
def recalculate_stats():
    """é‡æ–°è®¡ç®—ç»Ÿè®¡æ•°æ®ï¼ˆç”¨æˆ·æ‰‹åŠ¨å½’ç±»åè°ƒç”¨ï¼‰"""
    try:
        data = request.json
        if not data or 'celldata' not in data:
            return jsonify({'error': 'No celldata provided'}), 400
            
        celldata = data['celldata']
        print(f"[Recalculate] Received {len(celldata)} cells")
        
        # è§£æè¡¨æ ¼æ•°æ®
        # å‡è®¾æ ¼å¼: è¡Œ0æ˜¯è¡¨å¤´, åˆ—0=é—®é¢˜æ¦‚æ‹¬, åˆ—1=ç”¨æˆ·æƒ…ç»ª, åˆ—2=VOCåŸå£°
        rows_data = {}
        for cell in celldata:
            r, c = cell['r'], cell['c']
            if r == 0:  # è·³è¿‡è¡¨å¤´
                continue
            if r not in rows_data:
                rows_data[r] = {}
            rows_data[r][c] = cell['v']['v']
        
        # ç»Ÿè®¡: æŒ‰(é—®é¢˜æ¦‚æ‹¬, ç”¨æˆ·æƒ…ç»ª)åˆ†ç»„
        groups = {}
        total_rows = len(rows_data)
        
        for row_idx, row in rows_data.items():
            summary = row.get(0, 'æœªåˆ†ç±»')
            sentiment = row.get(1, 'ä¸­æ€§ğŸ˜')
            snippet = row.get(2, '')
            
            key = (summary, sentiment)
            if key not in groups:
                groups[key] = {
                    'summary': summary,
                    'sentiment': sentiment,
                    'user_count': 0,
                    'snippets': []
                }
            groups[key]['user_count'] += 1
            groups[key]['snippets'].append(snippet)
        
        # è®¡ç®—ç™¾åˆ†æ¯”å¹¶æ’åº
        result_list = []
        for key, group in groups.items():
            user_pct = (group['user_count'] / total_rows * 100) if total_rows > 0 else 0
            result_list.append({
                'summary': group['summary'],
                'sentiment': group['sentiment'],
                'user_count': group['user_count'],
                'user_pct': f"{user_pct:.2f}%",
                'snippets': group['snippets']
            })
        
        # æŒ‰ç”¨æˆ·æ•°é‡é™åºæ’åº
        result_list.sort(key=lambda x: x['user_count'], reverse=True)
        
        # æ„å»ºæ–°çš„celldataï¼ˆå¸¦ç»Ÿè®¡åˆ—ï¼‰
        new_celldata = []
        
        # è¡¨å¤´
        headers = ['é—®é¢˜æ¦‚æ‹¬', 'ç”¨æˆ·æƒ…ç»ª', 'ç”¨æˆ·æ•°é‡', 'ç”¨æˆ·å æ¯”', 'VOCåŸå£°ç‰‡æ®µ']
        for i, header in enumerate(headers):
            new_celldata.append({
                'r': 0,
                'c': i,
                'v': {
                    'v': header,
                    'm': header,
                    'ct': {'fa': 'General', 't': 'g'},
                    'bg': '#EDEBE9',
                    'bl': 1
                }
            })
        
        current_row = 1
        merge_config = {}
        
        # å¡«å……æ•°æ®
        for group in result_list:
            start_row = current_row
            rows_count = len(group['snippets'])
            
            # æ¯ä¸ªsnippetä¸€è¡Œ
            for snippet in group['snippets']:
                new_celldata.append({
                    'r': current_row,
                    'c': 4,  # VOCåŸå£°ç‰‡æ®µ
                    'v': {
                        'v': snippet,
                        'm': str(snippet),
                        'ct': {'fa': 'General', 't': 'g'}
                    }
                })
                current_row += 1
            
            # ç»Ÿè®¡åˆ—ï¼ˆåˆå¹¶å•å…ƒæ ¼ï¼‰
            # é—®é¢˜æ¦‚æ‹¬
            new_celldata.append({
                'r': start_row,
                'c': 0,
                'v': {
                    'v': group['summary'],
                    'm': group['summary'],
                    'ct': {'fa': 'General', 't': 'g'},
                    'vt': 1, 'ht': 1,
                    'bg': '#E6F2FF'
                }
            })
            
            # ç”¨æˆ·æƒ…ç»ªï¼ˆå¸¦é¢œè‰²ï¼‰
            font_color = '#000000'
            if 'è´Ÿé¢' in str(group['sentiment']):
                font_color = '#FF0000'
            elif 'æ­£é¢' in str(group['sentiment']):
                font_color = '#008000'
                
            new_celldata.append({
                'r': start_row,
                'c': 1,
                'v': {
                    'v': group['sentiment'],
                    'm': group['sentiment'],
                    'ct': {'fa': 'General', 't': 'g'},
                    'vt': 1, 'ht': 1,
                    'fc': font_color
                }
            })
            
            # ç”¨æˆ·æ•°é‡
            new_celldata.append({
                'r': start_row,
                'c': 2,
                'v': {
                    'v': group['user_count'],
                    'm': str(group['user_count']),
                    'ct': {'fa': 'General', 't': 'n'},
                    'vt': 1, 'ht': 1
                }
            })
            
            # ç”¨æˆ·å æ¯”
            new_celldata.append({
                'r': start_row,
                'c': 3,
                'v': {
                    'v': group['user_pct'],
                    'm': group['user_pct'],
                    'ct': {'fa': 'General', 't': 'g'},
                    'vt': 1, 'ht': 1
                }
            })
            
            # åˆå¹¶å•å…ƒæ ¼é…ç½®
            if rows_count > 1:
                for col_idx in range(4):
                    merge_config[f"{start_row}_{col_idx}"] = {
                        "r": start_row,
                        "c": col_idx,
                        "rs": rows_count,
                        "cs": 1
                    }
        
        result = {
            'name': 'åˆ†æç»“æœ',
            'status': 1,  # è®¾ç½®ä¸ºæ´»åŠ¨sheet
            'celldata': new_celldata,
            'config': {
                'merge': merge_config,
                'columnlen': {
                    '0': 200,  # é—®é¢˜æ¦‚æ‹¬
                    '1': 100,  # ç”¨æˆ·æƒ…ç»ª
                    '2': 70,   # ç”¨æˆ·æ•°é‡
                    '3': 70,   # ç”¨æˆ·å æ¯”
                    '4': 500   # VOCåŸå£°ç‰‡æ®µ
                }
            }
        }
        
        print(f"[Recalculate] Generated {len(new_celldata)} cells with {len(result_list)} groups")
        return jsonify(result), 200
        
    except Exception as e:
        print(f"[Recalculate] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
    
    # ä¿å­˜æ–‡ä»¶
    file_id = str(uuid.uuid4())
    file_path = os.path.join(UPLOAD_FOLDER, f'{file_id}.xlsx')
    file.save(file_path)
    
    # è¯»å–Excelæ–‡ä»¶å¹¶è½¬æ¢ä¸ºLuckysheetæ ¼å¼
    try:
        wb = load_workbook(file_path)
        sheets_data = []
        
        print(f"[ä¸Šä¼ ] å¼€å§‹å¤„ç†æ–‡ä»¶ï¼Œå…± {len(wb.sheetnames)} ä¸ªsheet")
        
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            cells = []
            
            print(f"[ä¸Šä¼ ] å¤„ç†sheet: {sheet_name}, æœ€å¤§è¡Œ: {ws.max_row}, æœ€å¤§åˆ—: {ws.max_column}")
            
            # è¯»å–æ‰€æœ‰æœ‰æ•°æ®çš„å•å…ƒæ ¼
            cell_count = 0
            for row_idx, row in enumerate(ws.iter_rows(values_only=False), start=1):
                for col_idx, cell in enumerate(row, start=1):
                    if cell.value is not None:
                        cells.append({
                            'r': row_idx - 1,
                            'c': col_idx - 1,
                            'v': {
                                'v': cell.value,
                                'm': str(cell.value),
                                'ct': {'fa': 'General', 't': 'g'}
                            }
                        })
                        cell_count += 1
            
            print(f"[ä¸Šä¼ ] Sheet {sheet_name} å…±è¯»å– {cell_count} ä¸ªå•å…ƒæ ¼")
            
            # è®¾ç½®åˆ—å®½
            # è®¾ç½®åˆ—å®½
            column = {}
            for col_idx in range(1, ws.max_column + 1):
                col_letter = get_column_letter(col_idx)
                width = ws.column_dimensions[col_letter].width if ws.column_dimensions[col_letter].width else 73
                # Luckysheet/FortuneSheet expects key to be string index "0", "1", etc.
                column[str(col_idx - 1)] = int(width) if width else 73
            
            sheet_data = {
                'name': sheet_name,
                'index': len(sheets_data),
                'order': len(sheets_data),
                'status': 1,
                'celldata': cells,
                'config': {
                    'columnlen': column,
                    'rowlen': {}
                },
                'scrollLeft': 0,
                'scrollTop': 0,
                'luckysheet_select_save': [],
                'calc chain': [],
                'isPivotTable': False,
                'pivotTable': {},
                'filter_select': None,
                'filter': None,
                'luckysheet_conditionformat_save': [],
                'frozen': {},
                'chart': [],
                'zoomRatio': 1,
                'image': [],
                'showGridLines': 1,
                'dataVerification': {}
            }
            sheets_data.append(sheet_data)
            print(f"[ä¸Šä¼ ] Sheet {sheet_name} æ•°æ®å·²æ·»åŠ åˆ°sheets_dataï¼Œcelldataæ•°é‡: {len(cells)}")
        
        print(f"[ä¸Šä¼ ] å‡†å¤‡è¿”å›æ•°æ®ï¼Œå…± {len(sheets_data)} ä¸ªsheet")
        result = {
            'fileId': file_id,
            'sheets': sheets_data,
            'originalSheets': wb.sheetnames
        }
        print(f"[ä¸Šä¼ ] è¿”å›æ•°æ®å¤§å°: {len(str(result))} å­—ç¬¦")
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': f'å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}'}), 500

@app.route('/api/analyze', methods=['POST'])
def analyze_voc():
    data = request.json
    file_id = data.get('fileId')
    
    if not file_id:
        return jsonify({'error': 'ç¼ºå°‘fileId'}), 400
    
    file_path = os.path.join(UPLOAD_FOLDER, f'{file_id}.xlsx')
    if not os.path.exists(file_path):
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    
    # å¦‚æœå·²æœ‰ä»»åŠ¡ï¼Œå…ˆåœæ­¢å®ƒ
    if file_id in analysis_tasks:
        analysis_tasks[file_id]['stop_flag'].set()
        # ç­‰å¾…æ—§ä»»åŠ¡ç»“æŸ
        analysis_tasks[file_id]['thread'].join(timeout=2)
    
    # åˆ›å»ºåœæ­¢æ ‡å¿—
    stop_flag = threading.Event()
    
    # åˆ›å»ºæ–°ä»»åŠ¡
    result_container = {'result': None, 'error': None, 'completed': False}
    
    def send_progress(current, total, message):
        """å‘é€è¿›åº¦æ›´æ–°"""
        progress = int((current / total * 100)) if total > 0 else 0
        return f"data: {json.dumps({'type': 'progress', 'current': current, 'total': total, 'progress': progress, 'message': message}, ensure_ascii=False)}\n\n"
    
    def analyze_task(progress_queue):
        try:
            print(f"[åˆ†æä»»åŠ¡] å¼€å§‹åˆ†ææ–‡ä»¶: {file_path}")
            # å‘é€åˆå§‹è¿›åº¦
            progress_queue.put(('progress', 0, 100, 'å¼€å§‹åˆ†æ...'))
            
            # è®¾ç½®åœæ­¢æ ‡å¿—åˆ°analyzer
            analyzer.set_stop_flag(stop_flag)
            
            # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
            def progress_callback(current, total, message):
                if not stop_flag.is_set():
                    print(f"[è¿›åº¦æ›´æ–°] {message} ({current}/{total})")
                    progress_queue.put(('progress', current, total, message))
            
            # åˆ†æVOCæ•°æ®
            print(f"[åˆ†æä»»åŠ¡] è°ƒç”¨ analyze_file...")
            analyzer.progress_callback = progress_callback
            analyzed_sheets = analyzer.analyze_file(file_path)
            print(f"[åˆ†æä»»åŠ¡] åˆ†æå®Œæˆï¼Œå¾—åˆ° {len(analyzed_sheets) if analyzed_sheets else 0} ä¸ªsheet")
            
            if stop_flag.is_set():
                print(f"[åˆ†æä»»åŠ¡] æ£€æµ‹åˆ°åœæ­¢æ ‡å¿—")
                result_container['error'] = 'åˆ†æè¢«ç”¨æˆ·ç»ˆæ­¢'
                progress_queue.put(('error', 'åˆ†æè¢«ç”¨æˆ·ç»ˆæ­¢'))
                return
            
            if not analyzed_sheets:
                print(f"[åˆ†æä»»åŠ¡] åˆ†æç»“æœä¸ºç©º")
                result_container['error'] = 'åˆ†æç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼'
                progress_queue.put(('error', 'åˆ†æç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼'))
                return
            
            result_container['result'] = {
                'fileId': file_id,
                'sheets': analyzed_sheets
            }
            print(f"[åˆ†æä»»åŠ¡] å‘é€å®Œæˆæ¶ˆæ¯ï¼ŒåŒ…å« {len(analyzed_sheets)} ä¸ªsheet")
            progress_queue.put(('complete', result_container['result']))
        except KeyboardInterrupt:
            print(f"[åˆ†æä»»åŠ¡] æ•è·åˆ° KeyboardInterrupt")
            result_container['error'] = 'åˆ†æè¢«ä¸­æ–­'
            progress_queue.put(('error', 'åˆ†æè¢«ä¸­æ–­'))
        except Exception as e:
            import traceback
            error_detail = str(e)
            print(f"[åˆ†æä»»åŠ¡] åˆ†æé”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·ç»ˆæ­¢
            if 'åˆ†æè¢«ç”¨æˆ·ç»ˆæ­¢' in error_detail or stop_flag.is_set():
                result_container['error'] = 'åˆ†æè¢«ç”¨æˆ·ç»ˆæ­¢'
                progress_queue.put(('error', 'åˆ†æè¢«ç”¨æˆ·ç»ˆæ­¢'))
            else:
                result_container['error'] = f'åˆ†æå¤±è´¥: {error_detail}'
                progress_queue.put(('error', result_container['error']))
        finally:
            result_container['completed'] = True
            progress_queue.put(('done', None))
            print(f"[åˆ†æä»»åŠ¡] ä»»åŠ¡å®Œæˆï¼Œæ¸…ç†èµ„æº")
            # æ¸…ç†ä»»åŠ¡
            if file_id in analysis_tasks:
                del analysis_tasks[file_id]
    
    # ä½¿ç”¨é˜Ÿåˆ—æ¥ä¼ é€’è¿›åº¦æ›´æ–°
    progress_queue = queue.Queue()
    
    # å¯åŠ¨åˆ†æçº¿ç¨‹
    thread = threading.Thread(target=analyze_task, args=(progress_queue,))
    thread.daemon = True
    thread.start()
    
    analysis_tasks[file_id] = {
        'stop_flag': stop_flag,
        'thread': thread
    }
    
    # ä½¿ç”¨SSEæµå¼å“åº”
    @stream_with_context
    def generate():
        print(f"[SSE] å¼€å§‹ç”Ÿæˆæµå¼å“åº” for file_id: {file_id}")
        timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶
        start_time = time.time()
        
        while True:
            try:
                # æ£€æŸ¥è¶…æ—¶
                if time.time() - start_time > timeout:
                    print(f"[SSE] è¶…æ—¶")
                    yield f"data: {json.dumps({'type': 'error', 'message': 'åˆ†æè¶…æ—¶'}, ensure_ascii=False)}\n\n"
                    break
                
                # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                if not thread.is_alive() and result_container['completed']:
                    # çº¿ç¨‹å·²å®Œæˆï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç»“æœ
                    print(f"[SSE] çº¿ç¨‹å·²å®Œæˆï¼Œæ£€æŸ¥ç»“æœ...")
                    if result_container['error']:
                        print(f"[SSE] å‘é€é”™è¯¯: {result_container['error']}")
                        yield f"data: {json.dumps({'type': 'error', 'message': result_container['error']}, ensure_ascii=False)}\n\n"
                    elif result_container['result']:
                        # å¦‚æœçº¿ç¨‹å®Œæˆä½†æ²¡æœ‰é€šè¿‡é˜Ÿåˆ—å‘é€completeæ¶ˆæ¯ï¼Œç›´æ¥å‘é€ç»“æœ
                        print(f"[SSE] å‘é€ç»“æœï¼ˆçº¿ç¨‹å·²å®Œæˆä½†æœªé€šè¿‡é˜Ÿåˆ—ï¼‰")
                        yield f"data: {json.dumps({'type': 'complete', 'data': result_container['result']}, ensure_ascii=False)}\n\n"
                    break
                
                # ä»é˜Ÿåˆ—è·å–è¿›åº¦æ›´æ–°ï¼ˆéé˜»å¡ï¼‰
                try:
                    update_type, *args = progress_queue.get(timeout=0.5)
                    print(f"[SSE] æ”¶åˆ°é˜Ÿåˆ—æ¶ˆæ¯: {update_type}")
                    
                    if update_type == 'progress':
                        current, total, message = args
                        progress = int((current / total * 100)) if total > 0 else 0
                        print(f"[SSE] å‘é€è¿›åº¦: {message} ({current}/{total}, {progress}%)")
                        yield f"data: {json.dumps({'type': 'progress', 'current': current, 'total': total, 'progress': progress, 'message': message}, ensure_ascii=False)}\n\n"
                    elif update_type == 'complete':
                        result = args[0]
                        print(f"[SSE] å‘é€å®Œæˆæ¶ˆæ¯ï¼ŒåŒ…å« {len(result.get('sheets', []))} ä¸ªsheet")
                        yield f"data: {json.dumps({'type': 'complete', 'data': result}, ensure_ascii=False)}\n\n"
                        break
                    elif update_type == 'error':
                        error_msg = args[0]
                        print(f"[SSE] å‘é€é”™è¯¯: {error_msg}")
                        yield f"data: {json.dumps({'type': 'error', 'message': error_msg}, ensure_ascii=False)}\n\n"
                        break
                    elif update_type == 'done':
                        print(f"[SSE] æ”¶åˆ°doneæ¶ˆæ¯")
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœéœ€è¦å‘é€
                        if result_container['result']:
                            print(f"[SSE] å‘é€ç»“æœï¼ˆdoneæ¶ˆæ¯åï¼‰")
                            yield f"data: {json.dumps({'type': 'complete', 'data': result_container['result']}, ensure_ascii=False)}\n\n"
                        break
                except queue.Empty:
                    # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                    continue
                    
            except Exception as e:
                import traceback
                print(f"[SSE] ç”Ÿæˆé”™è¯¯: {e}")
                print(traceback.format_exc())
                yield f"data: {json.dumps({'type': 'error', 'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'}, ensure_ascii=False)}\n\n"
                break
    
    return Response(generate(), mimetype='text/event-stream', headers={
        'Cache-Control': 'no-cache',
        'X-Accel-Buffering': 'no'
    })

@app.route('/api/analyze/stop', methods=['POST'])
def stop_analyze():
    data = request.json
    file_id = data.get('fileId')
    
    if not file_id:
        return jsonify({'error': 'ç¼ºå°‘fileId'}), 400
    
    if file_id in analysis_tasks:
        analysis_tasks[file_id]['stop_flag'].set()
        print(f"[åœæ­¢åˆ†æ] å·²è®¾ç½®åœæ­¢æ ‡å¿— for file_id: {file_id}")
        return jsonify({'message': 'åˆ†æå·²ç»ˆæ­¢'})
    else:
        return jsonify({'message': 'æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„åˆ†æä»»åŠ¡'})

if __name__ == '__main__':
    app.run(debug=True, port=5000)

