import openpyxl
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
import requests
import json
import re
import os

# å°è¯•å¯¼å…¥é…ç½®æ–‡ä»¶
try:
    from config import HF_API_TOKEN, TONGYI_API_KEY, TONGYI_MODEL, API_PRIORITY
except ImportError:
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
    HF_API_TOKEN = None
    TONGYI_API_KEY = None
    TONGYI_MODEL = "qwen-turbo"
    API_PRIORITY = ["hf_token", "tongyi", "hf_free", "local"]

class VOCAnalyzer:
    def __init__(self):
        # åŠ è½½APIé…ç½®
        self.hf_token = HF_API_TOKEN or os.getenv('HF_API_TOKEN')
        self.tongyi_key = TONGYI_API_KEY or os.getenv('TONGYI_API_KEY')
        # è·å–æ¨¡å‹åç§°ï¼Œå¦‚æœæœªé…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
        self.tongyi_model = TONGYI_MODEL if 'TONGYI_MODEL' in globals() else (os.getenv('TONGYI_MODEL') or "qwen-turbo")
        self.api_priority = API_PRIORITY
        
        # Hugging Face APIç«¯ç‚¹ï¼ˆä½¿ç”¨Tokenï¼‰
        self.hf_api_urls = [
            "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct",
            "https://api-inference.huggingface.co/models/Qwen/Qwen2-7B-Instruct",
            "https://api-inference.huggingface.co/models/Qwen/Qwen2-1.5B-Instruct",
            "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-14B-Instruct",
        ]
        
        # Hugging Faceå…è´¹APIç«¯ç‚¹ï¼ˆæ— éœ€Tokenï¼Œä½†å¯èƒ½ä¸å¯ç”¨ï¼‰
        self.hf_free_api_urls = [
            "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct",
            "https://api-inference.huggingface.co/models/Qwen/Qwen2-7B-Instruct",
            "https://api-inference.huggingface.co/models/Qwen/Qwen2-1.5B-Instruct",
        ]
        
        # é€šä¹‰åƒé—®APIç«¯ç‚¹
        self.tongyi_api_url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
        
        self.current_api_index = 0
        self.use_local_analysis = False
        self.stop_flag = None
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        print(f"[VOC Analyzer] åˆå§‹åŒ–å®Œæˆ")
        if self.hf_token:
            print(f"[VOC Analyzer] Hugging Face Tokenå·²é…ç½®")
        if self.tongyi_key:
            print(f"[VOC Analyzer] é€šä¹‰åƒé—®API Keyå·²é…ç½®ï¼Œæ¨¡å‹: {self.tongyi_model}")
        print(f"[VOC Analyzer] APIä¼˜å…ˆçº§: {', '.join(self.api_priority)}")
    
    def set_stop_flag(self, stop_flag):
        """è®¾ç½®åœæ­¢æ ‡å¿—"""
        self.stop_flag = stop_flag
    
    def analyze_with_ai(self, text):
        """ä½¿ç”¨Qwen AIåˆ†ææ–‡æœ¬æƒ…æ„Ÿå’Œåˆ†ç±»ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„API"""
        if self.use_local_analysis:
            return self.local_analyze(text)
        
        # æ„é€ prompt
        prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·åé¦ˆï¼Œè¿”å›JSONæ ¼å¼ç»“æœï¼š
{{
    "summary": "æ ‡å‡†åŒ–çš„é—®é¢˜åˆ†ç±»ï¼ˆè¯·åŠ¡å¿…ä½¿ç”¨é€šç”¨çš„çŸ­è¯­ï¼Œç¡®ä¿ç›¸ä¼¼é—®é¢˜è¢«å½’ä¸ºåŒä¸€ç±»ã€‚ä¾‹å¦‚ï¼š'ä¸»é¢˜æ•°é‡å°‘'å’Œ'æ¨¡æ¿ä¸è¶³'åº”ç»Ÿä¸€å½’ç±»ä¸º'ä¸»é¢˜å†…å®¹ä¸°å¯Œåº¦ä¸è¶³'ã€‚å…¶ä»–ç¤ºä¾‹ï¼šåŠŸèƒ½çµæ´»æ€§ç¼ºå¤±ã€ç™»å½•å¼‚å¸¸ã€é¡µé¢åŠ è½½æ…¢ï¼‰",
    "sentiment": "æ­£é¢ğŸ˜Š/è´Ÿé¢ğŸ˜ /ä¸­æ€§ğŸ˜"
}}

ç”¨æˆ·åé¦ˆï¼š{text}

è¯·åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼š"""
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„API
        for api_type in self.api_priority:
            if api_type == "hf_token" and self.hf_token:
                result = self._try_huggingface_token(prompt, text)
                if result:
                    return result
            elif api_type == "tongyi" and self.tongyi_key:
                result = self._try_tongyi_api(prompt, text)
                if result:
                    return result
            elif api_type == "hf_free":
                result = self._try_huggingface_free(prompt, text)
                if result:
                    return result
            elif api_type == "local":
                print("[Qwen API] ä½¿ç”¨æœ¬åœ°åˆ†æ")
                return self.local_analyze(text)
        
        # æ‰€æœ‰APIéƒ½å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°åˆ†æ
        print("[Qwen API] æ‰€æœ‰APIéƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°åˆ†æ")
        return self.local_analyze(text)
    
    def _try_huggingface_token(self, prompt, text):
        """å°è¯•ä½¿ç”¨Hugging Face API Token"""
        for api_url in self.hf_api_urls:
            try:
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.hf_token}"
                }
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 150,
                        "temperature": 0.3,
                        "return_full_text": False
                    }
                }
                
                print(f"[HF Token API] å°è¯•è°ƒç”¨: {api_url}")
                response = requests.post(api_url, headers=headers, json=payload, timeout=30)
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"[HF Token API] è°ƒç”¨æˆåŠŸ")
                    return self.parse_ai_result(result, text)
                elif response.status_code == 503:
                    error_info = response.json() if response.content else {}
                    estimated_time = error_info.get('estimated_time', 0)
                    print(f"[HF Token API] æ¨¡å‹æ­£åœ¨åŠ è½½ï¼Œé¢„è®¡ç­‰å¾…æ—¶é—´: {estimated_time}ç§’")
                    if estimated_time and estimated_time < 30:
                        import time
                        time.sleep(min(estimated_time + 2, 30))
                        retry_response = requests.post(api_url, headers=headers, json=payload, timeout=30)
                        if retry_response.status_code == 200:
                            return self.parse_ai_result(retry_response.json(), text)
                    continue
                else:
                    print(f"[HF Token API] é”™è¯¯ {response.status_code}: {response.text[:200]}")
                    continue
            except Exception as e:
                print(f"[HF Token API] è°ƒç”¨å¤±è´¥: {e}")
                continue
        return None
    
    def _try_tongyi_api(self, prompt, text):
        """å°è¯•ä½¿ç”¨é€šä¹‰åƒé—®API"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.tongyi_key}"
            }
            payload = {
                "model": self.tongyi_model,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹
                "input": {
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                },
                "parameters": {
                    "max_tokens": 150,
                    "temperature": 0.3
                }
            }
            
            print(f"[é€šä¹‰åƒé—®API] å°è¯•è°ƒç”¨æ¨¡å‹: {self.tongyi_model}")
            response = requests.post(self.tongyi_api_url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                print(f"[é€šä¹‰åƒé—®API] å“åº”çŠ¶æ€: 200")
                
                # é€šä¹‰åƒé—®APIçš„å“åº”æ ¼å¼å¯èƒ½æ˜¯ä¸¤ç§ï¼š
                # 1. æ–°æ ¼å¼: result['output']['text'] ç›´æ¥åŒ…å«æ–‡æœ¬
                # 2. æ—§æ ¼å¼: result['output']['choices'][0]['message']['content']
                generated_text = None
                
                if result.get('output'):
                    output = result['output']
                    # å°è¯•æ–°æ ¼å¼ï¼ˆtextå­—æ®µï¼‰
                    if 'text' in output:
                        generated_text = output['text']
                        print(f"[é€šä¹‰åƒé—®API] ä½¿ç”¨textå­—æ®µè·å–ç»“æœ")
                    # å°è¯•æ—§æ ¼å¼ï¼ˆchoiceså­—æ®µï¼‰
                    elif 'choices' in output and len(output['choices']) > 0:
                        generated_text = output['choices'][0]['message']['content']
                        print(f"[é€šä¹‰åƒé—®API] ä½¿ç”¨choiceså­—æ®µè·å–ç»“æœ")
                
                if generated_text:
                    print(f"[é€šä¹‰åƒé—®API] è°ƒç”¨æˆåŠŸï¼Œè¿”å›æ–‡æœ¬é•¿åº¦: {len(generated_text)}")
                    # è§£æç»“æœ
                    return self.parse_ai_result({'generated_text': generated_text}, text)
                else:
                    print(f"[é€šä¹‰åƒé—®API] å“åº”æ ¼å¼å¼‚å¸¸ï¼Œæœªæ‰¾åˆ°textæˆ–choices: {result}")
                    return None
            elif response.status_code == 429:
                # é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…åé‡è¯•
                error_info = response.json() if response.content else {}
                wait_time = 2  # é»˜è®¤ç­‰å¾…2ç§’
                print(f"[é€šä¹‰åƒé—®API] é€Ÿç‡é™åˆ¶(429)ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                import time
                time.sleep(wait_time)
                # é‡è¯•ä¸€æ¬¡
                retry_response = requests.post(self.tongyi_api_url, headers=headers, json=payload, timeout=30)
                if retry_response.status_code == 200:
                    result = retry_response.json()
                    if result.get('output'):
                        output = result['output']
                        if 'text' in output:
                            generated_text = output['text']
                        elif 'choices' in output and len(output['choices']) > 0:
                            generated_text = output['choices'][0]['message']['content']
                        else:
                            generated_text = None
                        
                        if generated_text:
                            print(f"[é€šä¹‰åƒé—®API] é‡è¯•æˆåŠŸ")
                            return self.parse_ai_result({'generated_text': generated_text}, text)
                print(f"[é€šä¹‰åƒé—®API] é‡è¯•åä»å¤±è´¥ï¼Œè¿”å›Noneä»¥å°è¯•ä¸‹ä¸€ä¸ªAPI")
                return None
            else:
                print(f"[é€šä¹‰åƒé—®API] é”™è¯¯ {response.status_code}: {response.text[:200]}")
                return None
        except Exception as e:
            print(f"[é€šä¹‰åƒé—®API] è°ƒç”¨å¤±è´¥: {e}")
            import traceback
            print(f"[é€šä¹‰åƒé—®API] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None
    
    def _try_huggingface_free(self, prompt, text):
        """å°è¯•ä½¿ç”¨Hugging Faceå…è´¹APIï¼ˆæ— éœ€Tokenï¼‰"""
        for api_url in self.hf_free_api_urls:
            try:
                headers = {"Content-Type": "application/json"}
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 150,
                        "temperature": 0.3,
                        "return_full_text": False
                    }
                }
                
                print(f"[HF Free API] å°è¯•è°ƒç”¨: {api_url}")
                response = requests.post(api_url, headers=headers, json=payload, timeout=30)
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"[HF Free API] è°ƒç”¨æˆåŠŸ")
                    return self.parse_ai_result(result, text)
                elif response.status_code == 503:
                    error_info = response.json() if response.content else {}
                    estimated_time = error_info.get('estimated_time', 0)
                    print(f"[HF Free API] æ¨¡å‹æ­£åœ¨åŠ è½½ï¼Œé¢„è®¡ç­‰å¾…æ—¶é—´: {estimated_time}ç§’")
                    if estimated_time and estimated_time < 30:
                        import time
                        time.sleep(min(estimated_time + 2, 30))
                        retry_response = requests.post(api_url, headers=headers, json=payload, timeout=30)
                        if retry_response.status_code == 200:
                            return self.parse_ai_result(retry_response.json(), text)
                    continue
                elif response.status_code == 410:
                    print(f"[HF Free API] æ¨¡å‹ä¸å¯ç”¨(410 - Gone)")
                    continue
                elif response.status_code == 429:
                    print(f"[HF Free API] è¯·æ±‚è¿‡å¤š(429)")
                    import time
                    time.sleep(2)
                    continue
                else:
                    print(f"[HF Free API] é”™è¯¯ {response.status_code}: {response.text[:200]}")
                    continue
            except Exception as e:
                print(f"[HF Free API] è°ƒç”¨å¤±è´¥: {e}")
                continue
        return None
    
    def local_analyze(self, text):
        """æœ¬åœ°è§„åˆ™åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        text_lower = text.lower()
        
        # æƒ…æ„Ÿåˆ†æå…³é”®è¯ï¼ˆæ›´å…¨é¢çš„ä¸­æ–‡å…³é”®è¯ï¼‰
        positive_keywords = ['å¥½', 'æ»¡æ„', 'å–œæ¬¢', 'æ¨è', 'ä¼˜ç§€', 'æ£’', 'èµ', 'ä¸é”™', 'å¾ˆå¥½', 'å®Œç¾', 
                            'èµ', 'ç»™åŠ›', 'å¥½ç”¨', 'æ–¹ä¾¿', 'å¿«æ·', 'æµç•…', 'æ¸…æ™°', 'ç¾è§‚', 'å®ç”¨', 
                            'è´´å¿ƒ', 'ä¸“ä¸š', 'é«˜æ•ˆ', 'ç¨³å®š', 'å¯é ', 'å€¼å¾—', 'è¶…å€¼', 'æƒŠå–œ']
        negative_keywords = ['å·®', 'ä¸å¥½', 'å¤±æœ›', 'é—®é¢˜', 'é”™è¯¯', 'æ…¢', 'å¡', 'å´©æºƒ', 'bug', 'æ•…éšœ',
                            'ç³Ÿç³•', 'åƒåœ¾', 'éš¾ç”¨', 'å¤æ‚', 'éº»çƒ¦', 'å»¶è¿Ÿ', 'å¡é¡¿', 'é—ªé€€', 'æ­»æœº',
                            'ä¸å…¼å®¹', 'ç¼ºå¤±', 'ä¸è¶³', 'ç¼ºé™·', 'æ¼æ´', 'ä¸å®‰å…¨', 'è´µ', 'ä¸å€¼']
        
        positive_count = sum(1 for kw in positive_keywords if kw in text)
        negative_count = sum(1 for kw in negative_keywords if kw in text)
        
        # åˆ¤æ–­æƒ…æ„Ÿ
        if positive_count > negative_count and positive_count > 0:
            sentiment = 'æ­£é¢'
        elif negative_count > 0:
            sentiment = 'è´Ÿé¢'
        else:
            sentiment = 'ä¸­æ€§'
        
        # ç®€å•åˆ†ç±»
        summary = self.categorize_text(text)
        
        # æ·»åŠ ç®€å•è¡¨æƒ…
        sentiment_emoji = {
            'æ­£é¢': 'æ­£é¢ğŸ˜Š',
            'è´Ÿé¢': 'è´Ÿé¢ğŸ˜ ',
            'ä¸­æ€§': 'ä¸­æ€§ğŸ˜'
        }
        
        return {
            'sentiment': sentiment_emoji.get(sentiment, sentiment),
            'summary': summary,
            'confidence': 0.7
        }
    
    def categorize_text(self, text):
        """ç®€å•çš„æ–‡æœ¬åˆ†ç±»"""
        text_lower = text.lower()
        
        categories = {
            'åŠŸèƒ½é—®é¢˜': ['åŠŸèƒ½', 'ä¸èƒ½', 'æ— æ³•', 'ä¸æ”¯æŒ', 'ç¼ºå°‘', 'æ²¡æœ‰', 'ç¼ºå¤±', 'ä¸å®Œå–„', 'ä¸å®Œæ•´', 'ç¼ºå°‘åŠŸèƒ½'],
            'æ€§èƒ½é—®é¢˜': ['æ…¢', 'å¡', 'å»¶è¿Ÿ', 'åŠ è½½', 'å“åº”', 'å¡é¡¿', 'å¡æ­»', 'è¿è¡Œæ…¢', 'é€Ÿåº¦', 'æ€§èƒ½', 'ä¼˜åŒ–'],
            'ç•Œé¢é—®é¢˜': ['ç•Œé¢', 'UI', 'è®¾è®¡', 'å¸ƒå±€', 'æ˜¾ç¤º', 'ç¾è§‚', 'æ ·å¼', 'é¢œè‰²', 'å­—ä½“', 'å›¾æ ‡', 'æŒ‰é’®'],
            'ä½“éªŒé—®é¢˜': ['ä½“éªŒ', 'ä½¿ç”¨', 'æ“ä½œ', 'æµç¨‹', 'æ–¹ä¾¿', 'æ˜“ç”¨', 'ç®€å•', 'å¤æ‚', 'éº»çƒ¦', 'é¡ºæ‰‹', 'ä¹ æƒ¯'],
            'æœåŠ¡é—®é¢˜': ['æœåŠ¡', 'å®¢æœ', 'æ”¯æŒ', 'å¸®åŠ©', 'å“åº”', 'æ€åº¦', 'å¤„ç†', 'å”®å', 'å’¨è¯¢', 'åé¦ˆ'],
            'ä»·æ ¼é—®é¢˜': ['ä»·æ ¼', 'è´¹ç”¨', 'æ”¶è´¹', 'è´µ', 'ä¾¿å®œ', 'æ€§ä»·æ¯”', 'ä»·å€¼', 'åˆ’ç®—', 'ä¸å€¼', 'å®šä»·'],
            'å…¶ä»–é—®é¢˜': []
        }
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„åŒ¹é…åˆ†æ•°
        category_scores = {}
        for category, keywords in categories.items():
            if category == 'å…¶ä»–é—®é¢˜':
                continue
            score = sum(1 for kw in keywords if kw in text)
            if score > 0:
                category_scores[category] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»åˆ«
        if category_scores:
            return max(category_scores.items(), key=lambda x: x[1])[0]
        
        return 'å…¶ä»–é—®é¢˜'
    
    def parse_ai_result(self, result, text):
        """è§£æQwenè¿”å›çš„ç»“æœ"""
        try:
            # Qwen2.5 APIè¿”å›æ ¼å¼å¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸
            generated_text = ""
            if isinstance(result, list) and len(result) > 0:
                if isinstance(result[0], dict):
                    generated_text = result[0].get('generated_text', '')
                else:
                    generated_text = str(result[0])
            elif isinstance(result, dict):
                generated_text = result.get('generated_text', '')
            else:
                generated_text = str(result)
            
            # å°è¯•ä»è¿”å›æ–‡æœ¬ä¸­æå–JSON
            # æŸ¥æ‰¾JSONå¯¹è±¡
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', generated_text)
            if json_match:
                json_str = json_match.group()
                parsed = json.loads(json_str)
                
                sentiment = parsed.get('sentiment', 'ä¸­æ€§ğŸ˜')
                summary = parsed.get('summary', 'å…¶ä»–é—®é¢˜')
                
                # ç§»é™¤æƒ…æ„Ÿæ ‡å‡†åŒ–å’Œåˆ†ç±»éªŒè¯ï¼Œç›´æ¥ä½¿ç”¨AIç”Ÿæˆçš„å†…å®¹
                
                return {
                    'sentiment': sentiment,
                    'summary': summary,
                    'confidence': 0.85
                }
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}, è¿”å›æ–‡æœ¬: {generated_text[:100]}")
        except Exception as e:
            print(f"è§£æQwenç»“æœå¤±è´¥: {e}, ä½¿ç”¨æœ¬åœ°åˆ†æ")
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°åˆ†æ
        return self.local_analyze(text)
    
    def analyze_and_categorize(self, file_path, progress_callback=None):
        """åˆ†æVOCæ–‡ä»¶å¹¶åˆ†ç±»
        
        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current, total, message) å‚æ•°
        """
        wb = load_workbook(file_path)
        sheets_data = []
        
        # å¤„ç†æ¯ä¸ªsheet
        for sheet_idx, sheet_name in enumerate(wb.sheetnames):
            ws = wb[sheet_name]
            
            # è¯»å–åŸå§‹æ•°æ®
            rows_data = []
            headers = []
            
            # è¯»å–ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
            first_row = next(ws.iter_rows(values_only=True), None)
            if first_row:
                headers = [str(cell) if cell else f'åˆ—{i+1}' for i, cell in enumerate(first_row)]
            
            # è¯»å–æ•°æ®è¡Œï¼ˆå‡è®¾ç”¨æˆ·åé¦ˆåœ¨ç¬¬äºŒåˆ—ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
            feedback_column_idx = 1  # é»˜è®¤ç¬¬äºŒåˆ—ï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰
            if len(headers) > 1:
                # å°è¯•æ‰¾åˆ°åŒ…å«"åé¦ˆ"ã€"æ„è§"ã€"è¯„è®º"ç­‰å…³é”®è¯çš„åˆ—
                for idx, header in enumerate(headers):
                    if any(keyword in str(header).lower() for keyword in ['åé¦ˆ', 'æ„è§', 'è¯„è®º', 'è¯„ä»·', 'å†…å®¹']):
                        feedback_column_idx = idx
                        break
            
            # è¯»å–æ‰€æœ‰æ•°æ®è¡Œ
            if progress_callback:
                progress_callback(0, 100, f'æ­£åœ¨è¯»å–å·¥ä½œè¡¨ "{sheet_name}"...')
            
            for row_idx, row in enumerate(ws.iter_rows(values_only=True), start=1):
                if row_idx == 1:
                    continue  # è·³è¿‡è¡¨å¤´
                
                if len(row) > feedback_column_idx and row[feedback_column_idx]:
                    feedback_text = str(row[feedback_column_idx]).strip()
                    if feedback_text:
                        rows_data.append({
                            'row_data': list(row),
                            'feedback': feedback_text,
                            'original_row': row_idx
                        })
            
            total_rows = len(rows_data)
            if progress_callback:
                progress_callback(0, total_rows, f'å¼€å§‹åˆ†æå·¥ä½œè¡¨ "{sheet_name}"ï¼Œå…± {total_rows} æ¡åé¦ˆ...')
            
            # å¯¹åé¦ˆè¿›è¡Œåˆ†ç±»
            categorized_data = {}
            for idx, row_info in enumerate(rows_data, 1):
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                if self.stop_flag and self.stop_flag.is_set():
                    print(f"[åœæ­¢åˆ†æ] æ£€æµ‹åˆ°åœæ­¢æ ‡å¿—ï¼Œç»ˆæ­¢åˆ†æ")
                    raise KeyboardInterrupt("åˆ†æè¢«ç”¨æˆ·ç»ˆæ­¢")
                
                # æ›´æ–°è¿›åº¦
                if progress_callback:
                    progress_callback(idx, total_rows, f'æ­£åœ¨åˆ†æç¬¬ {idx}/{total_rows} æ¡åé¦ˆ...')
                
                # è°ƒç”¨AIåˆ†æ
                analysis = self.analyze_with_ai(row_info['feedback'])
                
                # åœ¨APIè°ƒç”¨ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
                # é€šä¹‰åƒé—®APIæœ‰é€Ÿç‡é™åˆ¶ï¼Œæ¯æ¬¡è°ƒç”¨åç­‰å¾…0.3ç§’
                if self.tongyi_key and idx < total_rows:  # æœ€åä¸€æ¡ä¸éœ€è¦ç­‰å¾…
                    import time
                    time.sleep(0.3)
                
                # å†æ¬¡æ£€æŸ¥åœæ­¢æ ‡å¿—
                if self.stop_flag and self.stop_flag.is_set():
                    print(f"[åœæ­¢åˆ†æ] æ£€æµ‹åˆ°åœæ­¢æ ‡å¿—ï¼Œç»ˆæ­¢åˆ†æ")
                    raise KeyboardInterrupt("åˆ†æè¢«ç”¨æˆ·ç»ˆæ­¢")
                
                summary = analysis['summary']
                sentiment = analysis['sentiment']
                
                key = f"{summary}_{sentiment}"
                if key not in categorized_data:
                    categorized_data[key] = {
                        'summary': summary,
                        'sentiment': sentiment,
                        'rows': []
                    }
                categorized_data[key]['rows'].append(row_info)
            
            # åˆ›å»ºæ–°çš„sheetæ•°æ®
            new_sheet_name = f"{sheet_name}_åˆ†æç»“æœ"
            
            # å…ˆæ·»åŠ åŸå§‹sheet
            original_sheet_data = self.create_sheet_data(ws, sheet_name, sheet_idx)
            sheets_data.append(original_sheet_data)
            
            # åˆ›å»ºåˆ†æç»“æœsheet
            analyzed_sheet_data = self.create_analyzed_sheet(
                headers, categorized_data, new_sheet_name, len(sheets_data)
            )
            sheets_data.append(analyzed_sheet_data)
            
            # åˆ›å»ºåˆ†ç±»ç»Ÿè®¡sheet
            summary_sheet_name = f"{sheet_name}_åˆ†ç±»ç»Ÿè®¡"
            summary_sheet_data = self.create_category_summary_sheet(
                categorized_data, summary_sheet_name, len(sheets_data), total_rows
            )
            sheets_data.append(summary_sheet_data)
        
        return sheets_data
    
    def create_sheet_data(self, ws, sheet_name, index):
        """åˆ›å»ºåŸå§‹sheetçš„Luckysheetæ•°æ®"""
        cells = []
        
        for row_idx, row in enumerate(ws.iter_rows(values_only=False), start=1):
            for col_idx, cell in enumerate(row, start=1):
                if cell.value is not None:
                    cells.append({
                        'r': row_idx - 1,
                        'c': col_idx - 1,
                        'v': {
                            'v': cell.value,
                            'm': str(cell.value),
                            'ct': {'fa': 'General', 't': 'g'}
                        }
                    })
        
        column = {}
        for col_idx in range(1, ws.max_column + 1):
            col_letter = get_column_letter(col_idx)
            width = ws.column_dimensions[col_letter].width if ws.column_dimensions[col_letter].width else 73
            column[str(col_idx - 1)] = int(width) if width else 73
        
        return {
            'name': sheet_name,
            'index': index,
            'order': index,
            'status': 1,
            'celldata': cells,
            'config': {
                'columnlen': column,
                'rowlen': {}
            },
            'scrollLeft': 0,
            'scrollTop': 0,
            'luckysheet_select_save': [],
            'calc chain': [],
            'isPivotTable': False,
            'pivotTable': {},
            'filter_select': None,
            'filter': None,
            'luckysheet_conditionformat_save': [],
            'frozen': {},
            'chart': [],
            'zoomRatio': 1,
            'image': [],
            'showGridLines': 1,
            'dataVerification': {}
        }
    
    def create_analyzed_sheet(self, headers, categorized_data, sheet_name, index):
        """åˆ›å»ºåˆ†æç»“æœsheet"""
        cells = []
        merge_cells = []
        current_row = 0
        
        # æ·»åŠ è¡¨å¤´ - æ ¹æ®ç”¨æˆ·è¦æ±‚çš„æ ¼å¼
        # 1. é—®é¢˜æ¦‚æ‹¬ 2. ç”¨æˆ·æƒ…ç»ª 3. VOCåŸå£°
        custom_headers = ['é—®é¢˜æ¦‚æ‹¬', 'ç”¨æˆ·æƒ…ç»ª', 'VOCåŸå£°']
        for col_idx, header in enumerate(custom_headers):
            cells.append({
                'r': current_row,
                'c': col_idx,
                'v': {
                    'v': header,
                    'm': str(header),
                    'ct': {'fa': 'General', 't': 'g'}
                }
            })
        current_row += 1
        
        # æŒ‰åˆ†ç±»æ·»åŠ æ•°æ®
        for key in sorted(categorized_data.keys()):
            category_info = categorized_data[key]
            summary = category_info['summary']
            sentiment = category_info['sentiment']
            num_rows = len(category_info['rows'])
            
            if num_rows > 0:
                # æ·»åŠ é—®é¢˜æ¦‚æ‹¬ï¼ˆåˆå¹¶å•å…ƒæ ¼ï¼‰
                cells.append({
                    'r': current_row,
                    'c': 0,
                    'v': {
                        'v': summary,
                        'm': summary,
                        'ct': {'fa': 'General', 't': 'g'}
                    }
                })
                
                # æ·»åŠ ç”¨æˆ·æƒ…ç»ªï¼ˆåˆå¹¶å•å…ƒæ ¼ï¼‰
                cells.append({
                    'r': current_row,
                    'c': 1,
                    'v': {
                        'v': sentiment,
                        'm': sentiment,
                        'ct': {'fa': 'General', 't': 'g'}
                    }
                })
                
                # è®°å½•åˆå¹¶å•å…ƒæ ¼ä¿¡æ¯
                # åˆå¹¶ç¬¬ä¸€åˆ—ï¼ˆé—®é¢˜æ¦‚æ‹¬ï¼‰
                merge_cells.append({
                    'r': current_row,
                    'c': 0,
                    'rs': num_rows,
                    'cs': 1
                })
                
                # åˆå¹¶ç¬¬äºŒåˆ—ï¼ˆç”¨æˆ·æƒ…ç»ªï¼‰
                merge_cells.append({
                    'r': current_row,
                    'c': 1,
                    'rs': num_rows,
                    'cs': 1
                })
                
                # æ·»åŠ è¯¥åˆ†ç±»ä¸‹çš„æ‰€æœ‰è¡Œ - åªå±•ç¤ºVOCåŸå£°
                for row_info in category_info['rows']:
                    # ç¬¬3åˆ—ï¼šVOCåŸå£°
                    cells.append({
                        'r': current_row,
                        'c': 2,
                        'v': {
                            'v': row_info['feedback'],
                            'm': str(row_info['feedback']),
                            'ct': {'fa': 'General', 't': 'g'}
                        }
                    })
                    current_row += 1
        
        # è®¾ç½®åˆ—å®½
        column = {
            "0": 200,  # é—®é¢˜æ¦‚æ‹¬
            "1": 120,  # ç”¨æˆ·æƒ…ç»ª
            "2": 400   # VOCåŸå£°
        }
        
        return {
            'name': sheet_name,
            'index': index,
            'order': index,
            'status': 1,
            'celldata': cells,
            'config': {
                'columnlen': column,
                'rowlen': {}
            },
            'scrollLeft': 0,
            'scrollTop': 0,
            'luckysheet_select_save': [],
            'calc chain': [],
            'isPivotTable': False,
            'pivotTable': {},
            'filter_select': None,
            'filter': None,
            'luckysheet_conditionformat_save': [],
            'frozen': {},
            'chart': [],
            'zoomRatio': 1,
            'image': [],
            'showGridLines': 1,
            'dataVerification': {},
            'merge': merge_cells if merge_cells else {}
        }
    
    def create_category_summary_sheet(self, categorized_data, sheet_name, index, total_rows):
        """åˆ›å»ºVOCåˆ†ç±»ç»Ÿè®¡sheet"""
        cells = []
        current_row = 0
        
        # è¡¨å¤´
        headers = ['é—®é¢˜æ¦‚æ‹¬', 'ç”¨æˆ·æƒ…ç»ª', 'æ•°é‡', 'å æ¯”']
        for col_idx, header in enumerate(headers):
            cells.append({
                'r': current_row,
                'c': col_idx,
                'v': {
                    'v': header,
                    'm': header,
                    'ct': {'fa': 'General', 't': 'g'}
                }
            })
        current_row += 1
        
        # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„æ•°æ®
        summary_stats = {}
        for key, category_info in categorized_data.items():
            summary = category_info['summary']
            sentiment = category_info['sentiment']
            count = len(category_info['rows'])
            
            # æŒ‰åˆ†ç±»å’Œæƒ…æ„Ÿç»Ÿè®¡
            if summary not in summary_stats:
                summary_stats[summary] = {}
            if sentiment not in summary_stats[summary]:
                summary_stats[summary][sentiment] = 0
            summary_stats[summary][sentiment] += count
        
        # æŒ‰åˆ†ç±»åç§°æ’åº
        for summary in sorted(summary_stats.keys()):
            for sentiment in sorted(summary_stats[summary].keys()):
                count = summary_stats[summary][sentiment]
                percentage = (count / total_rows * 100) if total_rows > 0 else 0
                
                # é—®é¢˜æ¦‚æ‹¬
                cells.append({
                    'r': current_row,
                    'c': 0,
                    'v': {
                        'v': summary,
                        'm': summary,
                        'ct': {'fa': 'General', 't': 'g'}
                    }
                })
                
                # æƒ…æ„Ÿ
                cells.append({
                    'r': current_row,
                    'c': 1,
                    'v': {
                        'v': sentiment,
                        'm': sentiment,
                        'ct': {'fa': 'General', 't': 'g'}
                    }
                })
                
                # æ•°é‡
                cells.append({
                    'r': current_row,
                    'c': 2,
                    'v': {
                        'v': count,
                        'm': str(count),
                        'ct': {'fa': 'General', 't': 'n'}
                    }
                })
                
                # å æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼‰
                cells.append({
                    'r': current_row,
                    'c': 3,
                    'v': {
                        'v': percentage,
                        'm': f'{percentage:.2f}%',
                        'ct': {'fa': '0.00%', 't': 'n'}
                    }
                })
                
                current_row += 1
        
        # æ·»åŠ æ€»è®¡è¡Œ
        total_count = sum(len(info['rows']) for info in categorized_data.values())
        cells.append({
            'r': current_row,
            'c': 0,
            'v': {
                'v': 'æ€»è®¡',
                'm': 'æ€»è®¡',
                'ct': {'fa': 'General', 't': 'g'}
            }
        })
        cells.append({
            'r': current_row,
            'c': 1,
            'v': {
                'v': '-',
                'm': '-',
                'ct': {'fa': 'General', 't': 'g'}
            }
        })
        cells.append({
            'r': current_row,
            'c': 2,
            'v': {
                'v': total_count,
                'm': str(total_count),
                'ct': {'fa': 'General', 't': 'n'}
            }
        })
        cells.append({
            'r': current_row,
            'c': 3,
            'v': {
                'v': 100.0,
                'm': '100.00%',
                'ct': {'fa': '0.00%', 't': 'n'}
            }
        })
        
        # è®¾ç½®åˆ—å®½
        column = {
            "0": 120,  # åˆ†ç±»
            "1": 80,   # æƒ…æ„Ÿ
            "2": 80,   # æ•°é‡
            "3": 100   # å æ¯”
        }
        
        return {
            'name': sheet_name,
            'index': index,
            'order': index,
            'status': 1,
            'celldata': cells,
            'config': {
                'columnlen': column,
                'rowlen': {}
            },
            'scrollLeft': 0,
            'scrollTop': 0,
            'luckysheet_select_save': [],
            'calc chain': [],
            'isPivotTable': False,
            'pivotTable': {},
            'filter_select': None,
            'filter': None,
            'luckysheet_conditionformat_save': [],
            'frozen': {},
            'chart': [],
            'zoomRatio': 1,
            'image': [],
            'showGridLines': 1,
            'dataVerification': {}
        }
    

